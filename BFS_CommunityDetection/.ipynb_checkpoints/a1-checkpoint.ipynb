{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, deque\n",
    "import copy\n",
    "import math\n",
    "import networkx as nx\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_graph():\n",
    "    \"\"\"\n",
    "    Create the example graph from class. Used for testing.\n",
    "    Do not modify.\n",
    "    \"\"\"\n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'C'), ('B', 'D'), ('D', 'E'), ('D', 'F'), ('D', 'G'), ('E', 'F'), ('G', 'F')])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfs(graph, root, max_depth):\n",
    "    \"\"\"\n",
    "    Perform breadth-first search to compute the shortest paths from a root node to all\n",
    "    other nodes in the graph. To reduce running time, the max_depth parameter ends\n",
    "    the search after the specified depth.\n",
    "    E.g., if max_depth=2, only paths of length 2 or less will be considered.\n",
    "    This means that nodes greather than max_depth distance from the root will not\n",
    "    appear in the result.\n",
    "\n",
    "    You may use these two classes to help with this implementation:\n",
    "      https://docs.python.org/3.5/library/collections.html#collections.defaultdict\n",
    "      https://docs.python.org/3.5/library/collections.html#collections.deque\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      root........The root node in the search graph (a string). We are computing\n",
    "                  shortest paths from this node to all others.\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node that pass through this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "\n",
    "    In the doctests below, we first try with max_depth=5, then max_depth=2.\n",
    "\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 5)\n",
    "    >>> sorted(node2distances.items())\n",
    "    [('A', 3), ('B', 2), ('C', 3), ('D', 1), ('E', 0), ('F', 1), ('G', 2)]\n",
    "    >>> sorted(node2num_paths.items())\n",
    "    [('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]\n",
    "    >>> sorted((node, sorted(parents)) for node, parents in node2parents.items())\n",
    "    [('A', ['B']), ('B', ['D']), ('C', ['B']), ('D', ['E']), ('F', ['E']), ('G', ['D', 'F'])]\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 2)\n",
    "    >>> sorted(node2distances.items())\n",
    "    [('B', 2), ('D', 1), ('E', 0), ('F', 1), ('G', 2)]\n",
    "    >>> sorted(node2num_paths.items())\n",
    "    [('B', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]\n",
    "    >>> sorted((node, sorted(parents)) for node, parents in node2parents.items())\n",
    "    [('B', ['D']), ('D', ['E']), ('F', ['E']), ('G', ['D', 'F'])]\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    q = deque()\n",
    "    q.append(root)\n",
    "    _unode = []\n",
    "   \n",
    "    node2distances=defaultdict(int);\n",
    "    node2num_paths=defaultdict(int);\n",
    "    node2parents=defaultdict(list);\n",
    "    node2distances[root]=0\n",
    "    node2num_paths[root]=1\n",
    "    \n",
    "    while len(q) > 0:\n",
    "        _popnode = q.popleft()\n",
    "        for _nbrnode in graph.neighbors(_popnode):\n",
    "            if node2distances[_popnode]<max_depth:\n",
    "               \n",
    "                \n",
    "                if node2distances[_popnode] + 1<=node2distances[_nbrnode]:\n",
    "                    node2parents[_nbrnode].append(_popnode)\n",
    "                    node2num_paths[_nbrnode] = node2num_paths[_nbrnode] + 1  \n",
    "                \n",
    "                \n",
    "                if _nbrnode not in _unode and _nbrnode != root:\n",
    "                    node2num_paths[_nbrnode] = node2num_paths[_nbrnode] + 1\n",
    "                    node2parents[_nbrnode]= [_popnode]\n",
    "                    q.append(_nbrnode)\n",
    "                    _unode.append(_nbrnode)                  \n",
    "                    node2distances[_nbrnode] = node2distances[_popnode] + 1       \n",
    "    \n",
    "    return node2distances, node2num_paths, node2parents\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complexity_of_bfs(V, E, K):\n",
    "    \"\"\"\n",
    "    If V is the number of vertices in a graph, E is the number of\n",
    "    edges, and K is the max_depth of our approximate breadth-first\n",
    "    search algorithm, then what is the *worst-case* run-time of\n",
    "    this algorithm? As usual in complexity analysis, you can ignore\n",
    "    any constant factors. E.g., if you think the answer is 2V * E + 3log(K),\n",
    "    you would return V * E + math.log(K)\n",
    "    >>> v = complexity_of_bfs(13, 23, 7)\n",
    "    >>> type(v) == int or type(v) == float\n",
    "    True\n",
    "    \"\"\"\n",
    "    return V+E\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bottom_up(root, node2distances, node2num_paths, node2parents):\n",
    "    \"\"\"\n",
    "    Compute the final step of the Girvan-Newman algorithm.\n",
    "    See p 352 From your text:\n",
    "    https://github.com/iit-cs579/main/blob/master/read/lru-10.pdf\n",
    "        The third and final step is to calculate for each edge e the sum\n",
    "        over all nodes Y of the fraction of shortest paths from the root\n",
    "        X to Y that go through e. This calculation involves computing this\n",
    "        sum for both nodes and edges, from the bottom. Each node other\n",
    "        than the root is given a credit of 1, representing the shortest\n",
    "        path to that node. This credit may be divided among nodes and\n",
    "        edges above, since there could be several different shortest paths\n",
    "        to the node. The rules for the calculation are as follows: ...\n",
    "\n",
    "    Params:\n",
    "      root.............The root node in the search graph (a string). We are computing\n",
    "                       shortest paths from this node to all others.\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node that pass through this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "    Returns:\n",
    "      A dict mapping edges to credit value. Each key is a tuple of two strings\n",
    "      representing an edge (e.g., ('A', 'B')). Make sure each of these tuples\n",
    "      are sorted alphabetically (so, it's ('A', 'B'), not ('B', 'A')).\n",
    "\n",
    "      Any edges excluded from the results in bfs should also be exluded here.\n",
    "\n",
    "    >>> node2distances, node2num_paths, node2parents = bfs(example_graph(), 'E', 5)\n",
    "    >>> result = bottom_up('E', node2distances, node2num_paths, node2parents)\n",
    "    >>> sorted(result.items())\n",
    "    [(('A', 'B'), 1.0), (('B', 'C'), 1.0), (('B', 'D'), 3.0), (('D', 'E'), 4.5), (('D', 'G'), 0.5), (('E', 'F'), 1.5), (('F', 'G'), 0.5)]\n",
    "\n",
    "    \"\"\"\n",
    "    result = defaultdict(float)\n",
    "    dictionary = defaultdict(float)\n",
    "    node2distances = sorted(node2distances.items(),reverse = True, key = lambda x:x[1])\n",
    "    for (_unode, _) in node2distances:\n",
    "        if(_unode!=root):\n",
    "            dictionary[_unode]=dictionary[_unode]+1\n",
    "            for _vnode in node2parents[_unode]:\n",
    "                dictionary[_vnode] = dictionary[_vnode]+ dictionary[_unode] / node2num_paths[_unode]\n",
    "                result[tuple(sorted((_unode,_vnode)))] += dictionary[_unode]/node2num_paths[_unode]\n",
    "    return result\n",
    "\n",
    "   \n",
    "    ###TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_betweenness(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Compute the approximate betweenness of each edge, using max_depth to reduce\n",
    "    computation time in breadth-first search.\n",
    "\n",
    "    You should call the bfs and bottom_up functions defined above for each node\n",
    "    in the graph, and sum together the results. Be sure to divide by 2 at the\n",
    "    end to get the final betweenness.\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A dict mapping edges to betweenness. Each key is a tuple of two strings\n",
    "      representing an edge (e.g., ('A', 'B')). Make sure each of these tuples\n",
    "      are sorted alphabetically (so, it's ('A', 'B'), not ('B', 'A')).\n",
    "\n",
    "    >>> sorted(approximate_betweenness(example_graph(), 2).items())\n",
    "    [(('A', 'B'), 2.0), (('A', 'C'), 1.0), (('B', 'C'), 2.0), (('B', 'D'), 6.0), (('D', 'E'), 2.5), (('D', 'F'), 2.0), (('D', 'G'), 2.5), (('E', 'F'), 1.5), (('F', 'G'), 1.5)]\n",
    "    \"\"\"\n",
    "  \n",
    "    approx_betweenness = defaultdict(list)\n",
    "    _node = deque(graph.nodes())\n",
    "    while len(_node)>0:\n",
    "        _popnode = _node.pop()\n",
    "        node2distances, node2num_paths, node2parents = bfs(graph, _popnode, max_depth )\n",
    "        _bottmup = bottom_up(_popnode, node2distances, node2num_paths, node2parents)\n",
    "\n",
    "        for key in _bottmup:\n",
    "            if key in approx_betweenness:\n",
    "                approx_betweenness[key] = approx_betweenness[key]+_bottmup[key]\n",
    "            else:\n",
    "                approx_betweenness[key]= _bottmup[key]\n",
    "  \n",
    "  \n",
    "    for key in approx_betweenness:\n",
    "        approx_betweenness[key] = approx_betweenness[key]/2\n",
    "        \n",
    "       \n",
    "    return approx_betweenness\n",
    "\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_approximation_always_right():\n",
    "    \"\"\"\n",
    "    Look at the doctests for approximate betweenness. In this example, the\n",
    "    edge with the highest betweenness was ('B', 'D') for both cases (when\n",
    "    max_depth=5 and max_depth=2).\n",
    "\n",
    "    Consider an arbitrary graph G. For all max_depth > 1, will it always be\n",
    "    the case that the edge with the highest betweenness will be the same\n",
    "    using either approximate_betweenness verses the exact computation?\n",
    "    Answer this question below.\n",
    "\n",
    "    In this function, you just need to return either the string 'yes' or 'no'\n",
    "    (no need to do any actual computations here).\n",
    "    >>> s = is_approximation_always_right()\n",
    "    >>> type(s)\n",
    "    <class 'str'>\n",
    "    \"\"\"\n",
    "    return 'no'\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_girvan_newman(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Use your approximate_betweenness implementation to partition a graph.\n",
    "    Unlike in class, here you will not implement this recursively. Instead,\n",
    "    just remove edges until more than one component is created, then return\n",
    "    those components.\n",
    "    That is, compute the approximate betweenness of all edges, and remove\n",
    "    them until multiple comonents are created.\n",
    "\n",
    "    You only need to compute the betweenness once.\n",
    "    If there are ties in edge betweenness, break by edge name (e.g.,\n",
    "    (('A', 'B'), 1.0) comes before (('B', 'C'), 1.0)).\n",
    "\n",
    "    Note: the original graph variable should not be modified. Instead,\n",
    "    make a copy of the original graph prior to removing edges.\n",
    "    See the Graph.copy method https://networkx.github.io/documentation/development/reference/generated/networkx.Graph.copy.html\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A list of networkx Graph objects, one per partition.\n",
    "\n",
    "    >>> components = partition_girvan_newman(example_graph(), 5)\n",
    "    >>> components = sorted(components, key=lambda x: sorted(x.nodes())[0])\n",
    "    >>> sorted(components[0].nodes())\n",
    "    ['A', 'B', 'C']\n",
    "    >>> sorted(components[1].nodes())\n",
    "    ['D', 'E', 'F', 'G']\n",
    "      if graph.order() == 1:\n",
    "        return [graph.nodes()]\n",
    "    def find_best_edge(G0):\n",
    "        eb = nx.edge_betweenness_centrality(G0)\n",
    "        # eb is dict of (edge, score) pairs, where higher is better\n",
    "        # Return the edge with the highest score.\n",
    "        \n",
    "        return sorted(eb.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "    components = [c for c in nx.connected_component_subgraphs(graph)]\n",
    "    print(components)\n",
    "    indent = '   ' * max_depth  # for printing\n",
    "    while len(components) == 1:\n",
    "        edge_to_remove = find_best_edge(graph)\n",
    "        print(indent + 'removing ' + str(edge_to_remove))\n",
    "        graph.remove_edge(*edge_to_remove)\n",
    "        components = [c for c in nx.connected_component_subgraphs(graph)]\n",
    "    result = [c.nodes() for c in components]\n",
    "    print(indent + 'components=' + str(result))\n",
    "    \"\"\"\n",
    "    \n",
    "    ab = approximate_betweenness(graph, max_depth)\n",
    "    components = [c for c in nx.connected_component_subgraphs(graph)]\n",
    "    graph_copy = graph.copy()\n",
    "    sorted_dict = sorted(ab.items(), key = lambda x: (-x[1],x[0][0],x[0][1]))\n",
    "    for edge in sorted_dict:\n",
    "        if(len(components) > 1):\n",
    "            break\n",
    "        graph_copy.remove_edge(*(edge[0]))\n",
    "        components = [c for c in nx.connected_component_subgraphs(graph_copy)]\n",
    "    #print(len(components))\n",
    "    components[0],componenets[1] = componenets[1],componenets[0]\n",
    "    return components\n",
    "  \n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subgraph(graph, min_degree):\n",
    "    \"\"\"Return a subgraph containing nodes whose degree is\n",
    "    greater than or equal to min_degree.\n",
    "    We'll use this in the main method to prune the original graph.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx graph\n",
    "      min_degree...degree threshold\n",
    "    Returns:\n",
    "      a networkx graph, filtered as defined above.\n",
    "\n",
    "    >>> subgraph = get_subgraph(example_graph(), 3)\n",
    "    >>> sorted(subgraph.nodes())\n",
    "    ['B', 'D', 'F']\n",
    "    >>> len(subgraph.edges())\n",
    "    2\n",
    "    \"\"\"\n",
    "    \n",
    "    subgraph={}\n",
    "    degrees= nx.degree(graph)\n",
    "    for key, value in degrees.items():\n",
    "        if(value<min_degree):\n",
    "            graph.remove_node(key)\n",
    "    return graph\n",
    "    \n",
    "    ###TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Compute the normalized cut for each discovered cluster.\n",
    "I've broken this down into the three next methods.\n",
    "\"\"\"\n",
    "\n",
    "def volume(nodes, graph):\n",
    "    \"\"\"\n",
    "    Compute the volume for a list of nodes, which\n",
    "    is the number of edges in `graph` with at least one end in\n",
    "    nodes.\n",
    "    Params:\n",
    "      nodes...a list of strings for the nodes to compute the volume of.\n",
    "      graph...a networkx graph\n",
    "\n",
    "    >>> volume(['A', 'B', 'C'], example_graph())\n",
    "    4\n",
    "    \"\"\"\n",
    "    s=graph.edges(nodes)\n",
    "    volume=len(s)\n",
    "    return volume\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    Compute the cut-set of the cut (S,T), which is\n",
    "    the set of edges that have one endpoint in S and\n",
    "    the other in T.\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An int representing the cut-set.\n",
    "\n",
    "    >>> cut(['A', 'B', 'C'], ['D', 'E', 'F', 'G'], example_graph())\n",
    "    1\n",
    "    \"\"\"\n",
    "    cut = 0\n",
    "    for _node1 in S:\n",
    "        for _node2 in T:\n",
    "            edge=(_node1,_node2)\n",
    "            if graph.has_edge(*edge):\n",
    "                cut+=1\n",
    "    return cut\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    The normalized cut value for the cut S/T. (See lec06.)\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An float representing the normalized cut value\n",
    "\n",
    "    \"\"\"\n",
    "    norm_cut = (cut(S, T, graph)/volume(S,graph)) + (cut(S,T,graph)/volume(T,graph))\n",
    "    return norm_cut\n",
    "\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_max_depths(graph, max_depths):\n",
    "    \"\"\"\n",
    "    In order to assess the quality of the approximate partitioning method\n",
    "    we've developed, we will run it with different values for max_depth\n",
    "    and see how it affects the norm_cut score of the resulting partitions.\n",
    "    Recall that smaller norm_cut scores correspond to better partitions.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx Graph\n",
    "      max_depths...a list of ints for the max_depth values to be passed\n",
    "                   to calls to partition_girvan_newman\n",
    "\n",
    "    Returns:\n",
    "      A list of (int, float) tuples representing the max_depth and the\n",
    "      norm_cut value obtained by the partitions returned by\n",
    "      partition_girvan_newman. See Log.txt for an example.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    new_graph = graph.copy()\n",
    "    score_max_depths = []\n",
    "    for depth in max_depths:\n",
    "        partitions = partition_girvan_newman(graph, depth)\n",
    "        S = partitions[0]\n",
    "        T = partitions[1]\n",
    "        score_max_depths.append((depth,norm_cut(S, T, new_graph)))\n",
    "    return score_max_depths\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Link prediction\n",
    "\n",
    "# Next, we'll consider the link prediction problem. In particular,\n",
    "# we will remove 5 of the accounts that Bill Gates likes and\n",
    "# compute our accuracy at recovering those links.\n",
    "\n",
    "def make_training_graph(graph, test_node, n):\n",
    "    \"\"\"\n",
    "    To make a training graph, we need to remove n edges from the graph.\n",
    "    As in lecture, we'll assume there is a test_node for which we will\n",
    "    remove some edges. Remove the edges to the first n neighbors of\n",
    "    test_node, where the neighbors are sorted alphabetically.\n",
    "    E.g., if 'A' has neighbors 'B' and 'C', and n=1, then the edge\n",
    "    ('A', 'B') will be removed.\n",
    "\n",
    "    Be sure to *copy* the input graph prior to removing edges.\n",
    "\n",
    "    Params:\n",
    "      graph.......a networkx Graph\n",
    "      test_node...a string representing one node in the graph whose\n",
    "                  edges will be removed.\n",
    "      n...........the number of edges to remove.\n",
    "\n",
    "    Returns:\n",
    "      A *new* networkx Graph with n edges removed.\n",
    "\n",
    "    In this doctest, we remove edges for two friends of D:\n",
    "    >>> g = example_graph()\n",
    "    >>> sorted(g.neighbors('D'))\n",
    "    ['B', 'E', 'F', 'G']\n",
    "    >>> train_graph = make_training_graph(g, 'D', 2)\n",
    "    >>> sorted(train_graph.neighbors('D'))\n",
    "    ['F', 'G']\n",
    "     t_graph=graph.copy()\n",
    "    _nbrnode = sorted(graph.neighbors(test_node))\n",
    "    new_graph=[t_graph.remove_edge(_nbrnode[x],test_node) for x in range(0,n)]\n",
    "     \n",
    "    \"\"\"\n",
    "    new_graph = graph.copy()\n",
    "    neighbors = sorted(new_graph.neighbors(test_node))\n",
    "    for i in range(0,n):\n",
    "        edge=(neighbors[i],test_node)\n",
    "        new_graph.remove_edge(*edge)\n",
    "    return new_graph\n",
    "\n",
    "    ###TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(graph, node, k):\n",
    "    \"\"\"\n",
    "    Compute the k highest scoring edges to add to this node based on\n",
    "    the Jaccard similarity measure.\n",
    "    Note that we don't return scores for edges that already appear in the graph.\n",
    "\n",
    "    Params:\n",
    "      graph....a networkx graph\n",
    "      node.....a node in the graph (a string) to recommend links for.\n",
    "      k........the number of links to recommend.\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples in descending order of score representing the\n",
    "      recommended new edges. Ties are broken by\n",
    "      alphabetical order of the terminal node in the edge.\n",
    "\n",
    "    In this example below, we remove edges (D, B) and (D, E) from the\n",
    "    example graph. The top two edges to add according to Jaccard are\n",
    "    (D, E), with score 0.5, and (D, A), with score 0. (Note that all the\n",
    "    other remaining edges have score 0, but 'A' is first alphabetically.)\n",
    "\n",
    "    >>> g = example_graph()\n",
    "    >>> train_graph = make_training_graph(g, 'D', 2)\n",
    "    >>> jaccard(train_graph, 'D', 2)\n",
    "    [(('D', 'E'), 0.5), (('D', 'A'), 0.0)]\n",
    "    \"\"\"\n",
    "    jaccard_scores = []\n",
    "    neighbors = set(graph.neighbors(node))\n",
    "    for n in graph.nodes():\n",
    "        if node!=n and not graph.has_edge(node, n):\n",
    "            neighbors2 = set(graph.neighbors(n))\n",
    "            jaccard_scores.append(((node, n), len(neighbors & neighbors2) / len(neighbors | neighbors2)))\n",
    "    return sorted(jaccard_scores, key=lambda x: (-x[1],x[0]))[:k]\n",
    "    ###TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One limitation of Jaccard is that it only has non-zero values for nodes two hops away.\n",
    "#\n",
    "# Implement a new link prediction function that computes the similarity between two nodes $x$ and $y$  as follows:\n",
    "#\n",
    "# $$\n",
    "# s(x,y) = \\beta^i n_{x,y,i}\n",
    "# $$\n",
    "#\n",
    "# where\n",
    "# - $\\beta \\in [0,1]$ is a user-provided parameter\n",
    "# - $i$ is the length of the shortest path from $x$ to $y$\n",
    "# - $n_{x,y,i}$ is the number of shortest paths between $x$ and $y$ with length $i$\n",
    "\n",
    "\n",
    "def path_score(graph, root, k, beta):\n",
    "    \"\"\"\n",
    "    Compute a new link prediction scoring function based on the shortest\n",
    "    paths between two nodes, as defined above.\n",
    "\n",
    "    Note that we don't return scores for edges that already appear in the graph.\n",
    "\n",
    "    This algorithm should have the same time complexity as bfs above.\n",
    "\n",
    "    Params:\n",
    "      graph....a networkx graph\n",
    "      root.....a node in the graph (a string) to recommend links for.\n",
    "      k........the number of links to recommend.\n",
    "      beta.....the beta parameter in the equation above.\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples in descending order of score. Ties are broken by\n",
    "      alphabetical order of the terminal node in the edge.\n",
    "\n",
    "    In this example below, we remove edge (D, F) from the\n",
    "    example graph. The top two edges to add according to path_score are\n",
    "    (D, F), with score 0.5, and (D, A), with score .25. (Note that (D, C)\n",
    "    is tied with a score of .25, but (D, A) is first alphabetically.)\n",
    "\n",
    "    >>> g = example_graph()\n",
    "    >>> train_graph = g.copy()\n",
    "    >>> train_graph.remove_edge(*('D', 'F'))\n",
    "    >>> path_score(train_graph, 'D', k=4, beta=.5)\n",
    "    [(('D', 'F'), 0.5), (('D', 'A'), 0.25), (('D', 'C'), 0.25)]\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    path_scores=[]\n",
    "    node2distances, node2num_paths, node2parents = bfs(graph, root, math.inf)    \n",
    "    for node in graph.nodes():\n",
    "        if root!=node and not graph.has_edge(root, node):\n",
    "            path_scores.append(((root, node), (beta ** node2distances[node]) * node2num_paths[node]))\n",
    "    return sorted(path_scores, key=lambda x: (-x[1],x[0]))[:k]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(predicted_edges, graph):\n",
    "    \"\"\"\n",
    "    Return the fraction of the predicted edges that exist in the graph.\n",
    "\n",
    "    Args:\n",
    "      predicted_edges...a list of edges (tuples) that are predicted to\n",
    "                        exist in this graph\n",
    "      graph.............a networkx Graph\n",
    "\n",
    "    Returns:\n",
    "      The fraction of edges in predicted_edges that exist in the graph.\n",
    "\n",
    "    In this doctest, the edge ('D', 'E') appears in the example_graph,\n",
    "    but ('D', 'A') does not, so 1/2 = 0.5\n",
    "\n",
    "    >>> evaluate([('D', 'E'), ('D', 'A')], example_graph())\n",
    "    0.5\n",
    "    \"\"\"\n",
    "    return len([e for e in predicted_edges if graph.has_edge(*e)]) / len(predicted_edges)\n",
    "    ###TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Next, we'll download a real dataset to see how our algorithm performs.\n",
    "\"\"\"\n",
    "def download_data():\n",
    "    \"\"\"\n",
    "    Download the data. Done for you.\n",
    "    \"\"\"\n",
    "    urllib.request.urlretrieve('http://cs.iit.edu/~culotta/cs579/a1/edges.txt.gz', 'edges.txt.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_graph():\n",
    "    \"\"\" Read 'edges.txt.gz' into a networkx **undirected** graph.\n",
    "    Done for you.\n",
    "    Returns:\n",
    "      A networkx undirected graph.\n",
    "    \"\"\"\n",
    "  \n",
    "    return nx.read_edgelist('edges.txt.gz', delimiter='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph has 5062 nodes and 6060 edges\n",
      "subgraph has 712 nodes and 1710 edges\n",
      "norm_cut scores by max_depth:\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "[(1, 1.0070175438596491), (2, 1.0005847953216374), (3, 0.12177725118483412), (4, 0.12177725118483412)]\n",
      "2\n",
      "first partition: cluster 1 has 11 nodes and cluster 2 has 701 nodes\n",
      "cluster 2 nodes:\n",
      "['ActionAid UK', 'GivingTuesday', 'TED Radio Hour', 'Generosity Day', 'Universalist Unitarian Church of Peoria, Illinois', 'Barbara Lee', 'United Nations in Thailand', 'CARE', 'Unicef Liberia', 'AGRA Alliance', 'World Health Summit', 'TIME Photo', 'Center for Civic Education', 'Scientific American magazine', 'Wisconsin Council for the Social Studies (WCSS)', 'World Food Programme', 'Comic Relief: Red Nose Day', 'Facebook Developers', 'Women in Public Service', 'Mother Jones', 'International Space Station', 'Lockheed Martin', 'Speak Up Africa', 'Mic', 'Team GB', 'Sue Desmond-Hellmann', 'UNMEER', 'Amazon Smile', 'Grassroot Soccer', 'Longreads', 'Derby-Shelton Rotary Club', 'Rio+20 UN Conference on Sustainable Development', 'UN Peacekeeping', 'End Polio Now', 'FOX Sports', 'Katharine McPhee', 'John Green', 'Bustle', 'Qatar Foundation', 'Guardian US', 'Big History Project', 'يونيسف – اليمن UNICEF Yemen', 'National Geographic Education', 'The Wall Street Journal', 'Microsoft Imagine', 'The Lancet', 'Day of the Girl Summit', 'International Labour Organization (ILO)', 'Greenpeace International', 'Committee for Children', 'Microsoft Store', 'Discovery', 'Lutheran Malaria Initiative', 'California Council for the Social Studies', 'Women in the World', 'Seattle Met Magazine', '公益財団法人日本ユニセフ協会', 'Eminence', 'Agency', 'Forbes', 'Foro Económico Mundial', 'MSN', 'Family Planning 2020', 'Rotary Club of Rancho Bernardo', 'Global Education & Skills Forum', 'Abdul Latif Jameel Poverty Action Lab (J-PAL)', 'Young Global Leaders', 'Christiane Amanpour', 'The New Yorker', 'UN-Water World Water Day', 'Rotaract Club of Makati Legaspi', 'United Nations Foundation', 'CNN', 'Canada is Dedicated to International Development - DFATD', 'VillageReach', 'Live Below the Line', 'Stop TB Partnership', 'World YWCA', 'Slate.com', 'The Insatiable Traveler', 'One Billion Hungry: Can We Feed the World?', 'International Justice Mission', 'WE CARE Solar', 'Novartis', 'Magnum Photos', 'Facebook for Business', 'Malô', 'streetfootballworld', 'Global Shapers Community - Quito, Ecuador Hub', 'USAID for Global Health', 'Sylvia A. Earle', 'Bing', 'Roll Back Malaria', 'UN Women Pacific', 'Rotaract Club of New York at the United Nations', 'United Nations in Belarus', 'Rotary Peace Centers', 'OCSS - The Oregon Council for the Social Studies', 'Facing the Future', 'UNICEF Central African Republic', 'Maternity Worldwide', 'International Initiative for Impact Evaluation (3ie)', 'Girls Not Brides', 'WWF', 'KA Lite', \"Samuel Eto'o\", 'Global Communities', 'World Wildlife Fund', 'UN Geneva', 'Stomp Out Malaria', 'Nonprofit Organizations', 'The Global Fund for Women', 'World Federation of United Nations Associations', 'Intel', \"Girls' Globe\", 'ASUS', 'NPR', 'Girls Who Code', 'Instagram', 'Microsoft', 'Rotary Reconnect', '2Pocket Fairtrade', \"Amy Poehler's Smart Girls\", 'Ripple Effect Images', 'EA SPORTS', 'Clinton Global Initiative', 'Vital Voices', 'UNICEF UK', 'European Commission - Development & Cooperation - EuropeAid', 'Duke Basketball', 'The Onion', 'Daily Development', 'One Day On Earth', 'International Committee of the Red Cross', 'HeForShe', 'Lewis Hamilton', 'Africa Inside Out', 'NPR Morning Edition', 'Unicef Somalia', 'Endangered Species Protection - RAGES', 'Melinda Gates', 'United Nations News Centre', 'The Global Goals', 'TIME', 'BBC Newsnight', 'Gerard Piqué', 'loveLife', 'BBC News Magazine', 'GroupMe', 'NBC', 'Kentucky Council for the Social Studies', 'GBCHealth', 'MY World', 'Al Jazeera Channel - قناة الجزيرة الفضائية', 'Facebook Media', 'General Colin L. Powell', 'SK - Sports India', 'SOTENI International', 'UNHCR', \"Women's Major Group\", 'PBS', 'The MasterCard Foundation', 'World Health Organization', 'Clinton Bush Haiti Fund', 'Women Deliver', 'Trees, Water & People', 'Cordaid', 'NASA - National Aeronautics and Space Administration', 'Upworthy', 'ONE', 'Tanya Plibersek', 'Al Gore', 'Clinton Foundation', 'Connect4Climate', 'United Nations Millennium Campaign Africa', 'The Rachel Maddow Show', 'Rotary Italia', 'FIFA Ultimate Team', 'The White House', 'Utah Science Teachers Association', 'United Nations Human Rights', 'Infosys', 'UNICEF Haiti', 'GAVI CSO', 'National Geographic Learning', \"Office of the UN Secretary-General's Envoy on Youth\", 'UNDP in the Pacific and PNG', 'Foreign Affairs', 'Save the Children UK', 'CDC Global', 'Stanford Social Innovation Review', 'I fucking love science', 'Every Mother Counts', 'California Geographic Alliance', 'MarketingProfs', 'Sports Illustrated', 'D.light Design', 'UNICEF Africa', 'United Nations', 'Global Alliance for Clean Cookstoves', 'UNICEF Jordan', 'ClickHole', 'Les Miserables - Musical', 'World Bank', 'UNFCCC', 'Westfield Century City', 'Charlie Rose', 'Virginia Council for the Social Studies', 'Reagan Library', 'Bring Back Our Girls', 'Grameen Foundation', 'Governor-General of New Zealand', 'RESULTS', 'The New York Times', 'The Dow Chemical Company', 'U.S. Department of State: Engaging the Community on Foreign Affairs', 'Bill & Melinda Gates Foundation Visitor Center', \"Malawi Children's Village\", 'PGA TOUR Golf Challenge', \"NPR's Weekend Edition\", \"General Federation of Women's Clubs\", 'Concern Worldwide', 'Real Madrid C.F.', 'Scaling Up Nutrition Movement', 'WNYC Radio', 'Pulitzer Center on Crisis Reporting', 'Digg', 'U.S. Department of State: Bureau of African Affairs', 'The National Press Club', 'Intrepid Sea, Air & Space Museum', 'Wheels of Hope', 'Overseas Development Institute (ODI)', 'The Good Men Project', 'Global Citizen', 'Entrepreneur', 'National History Day', 'Chase', 'Panasonic', 'Rotary Club of Wall Street New York', 'San Joaquin Valley Council for the Social Studies (SJVCSS)', 'Xbox Entertainment', 'IRIN', 'Malaria No More', 'National Science Teachers Association', 'Evidence Action', 'The New York Times Opinion Section', 'Global Shapers - San Salvador Hub', 'Emma Watson', 'Quartz', 'DefeatDD', 'Surface', 'Day of the Girl', 'Radio Diaries', 'Children and Youth International', 'Willie Nelson', 'Stone Oak Rotary Club', 'The Better World Campaign', 'National History Day California', 'UNDP Albania', 'One Billion Rising', 'Global Shapers - Santo Domingo Hub', 'Washington State Council for the Social Studies', 'Gabi Weber', 'Unicef Rwanda', 'U.S. Department of Agriculture', 'Baker City Rotary Club', 'Gpange', 'Donate My Card', 'American Cancer Society', 'The Economist', 'Skype in the classroom', 'Nothing But Nets', 'Institute for Health Metrics and Evaluation (IHME)', 'Rotary International', 'STEMconnector', 'Room to Read: World Change Starts with Educated Children (Official)', 'Bill Nye The Science Guy', 'UNICEF Kenya', 'Food and Agriculture Organization of the United Nations (FAO)', 'Heifer International', 'PeopleImeet', 'Pike Place Market', 'University of Washington', 'YouthCare', 'The Bill of Rights Institute', 'UNICEF New Zealand', 'Ezra Klein', 'BlogHer', 'Grace Hopper Celebration of Women in Computing', 'Social Good', 'UNICEF Nepal', 'Bill Gates', 'Bond_Free', 'Burke Museum', 'Rio+20', 'Medium', 'The Maternal and Child Survival Program', 'Clinton Presidential Center', 'Red Nose Day USA', 'Bleacher Report', 'CGAP - Consultative Group to Assist the Poor', 'World Health Organization (WHO)', 'WHO Regional Office for Europe', 'Global Accelerator', 'The Atlantic', 'Acer', 'INSEAD Knowledge', 'National Geographic', 'Simply Measured', 'Girl Effect', 'Chelsea Clinton', 'Overseas Private Investment Corporation', 'Kickstarter', 'Friends of the Global Fund Africa', 'Lenovo', 'Napkin Labs', 'Global Health Council', 'US National Archives', 'PATH', 'Qualcomm', 'Momentum1000', 'Megan Hilty Online', 'Sasha Alexander', 'Zinduka! Malaria Haikubaliki', 'Jeffrey Sachs', 'Vaccines Today', 'UNODC - United Nations Office on Drugs and Crime', 'Co.Exist', 'Colorado Geographic Alliance', 'Georgia Council for the Social Studies (GCSS)', 'RESULTS AU', 'Google', 'United Nations Visitors Centre', 'ICDDR,B', 'Sustainable Energy for All', 'Girl Up', 'Martha MacCallum', 'Global Health Strategies', 'Save the Children', 'Facebook', 'Shiva Thapa', 'Nokia', 'Hubble Space Telescope', 'Chevron', \"Shaquille O' Neal\", 'TED', 'UN Women Asia and the Pacific', '350.org', 'Lean In', 'Aeras', 'U.S. Senator Lindsey Graham', 'Grand Challenges Canada', 'UNICEF USA', 'Invisible Children', 'The Choices Program', 'Washington Post', 'Unicef Polio', 'StopBullying.Gov', 'Pandora', 'African Green Revolution Forum', 'Panasonic UK', 'UNIDO - United Nations Industrial Development Organization', 'Show of Force: Social Good', 'Spotify', 'PBS NewsHour', 'UNICEF Australia', 'The Olympic Games', 'Global Moms Challenge', 'North American Power', 'HISTORY', 'Beyond Access', 'Lalela Project', 'International Center for Journalists', 'NCWIT Aspirations in Computing', 'indieWIRE', 'Fareed Zakaria', 'Google Chrome', 'Jackson Heights Rotary Club', 'Interact Club Illyrian', 'Microsoft Excel', 'International Fund for Agricultural Development (IFAD)', 'Cancer', 'U.S. Department of State', 'HuffPost Impact', 'Action/2015', 'Skype', 'GOOD', 'Global Goals for Sustainable Development', 'CES', 'The Commonwealth', 'United Nations Economic and Social Council', 'Nicholas Kristof', 'U.S. Department of State:  Bureau of Population, Refugees, and Migration', 'United Nations Assistance Mission for Iraq (UNAMI)', 'The New York Times - The Learning Network', 'CeeLo Green', 'World Animal Protection', 'Green on Facebook', 'Catapult', 'Levo League', 'Greenpeace Rainbow Warrior', 'The Independent', 'Close the Global Gender Gap', 'Swiss Malaria Foundation', 'Smash', 'Unicef Myanmar', 'Team Gleason', 'Darren Ornitz Photography', 'myweku.com', 'Mobile Alliance for Maternal Action - MAMA Global', 'National Oceanic and Atmospheric Administration (NOAA)', 'Entertainment Weekly', 'Peace Corps', 'Elizabeth Glaser Pediatric AIDS Foundation', 'TechSoup', 'Being Liberal', 'CGI U', 'Together for Girls', 'Complex Sports', 'Schwab Foundation for Social Entrepreneurship', 'United Against Malaria', 'EFA Report UNESCO', 'Ellen DeGeneres', 'Maria Grazia Cucinotta', 'International Partnership for Microbicides', 'MADE in Europe', 'UNICEF Guinea', 'Department of State - Bureau of Democracy, Human Rights and Labor', 'TED Live', 'Burn the Rope', 'Duke University', 'VSO', 'The Daily Show', 'Facebook in Education', 'State Department- Bureau of International Security and Nonproliferation', 'UN Sustainable Development Knowledge Platform', 'Comic Relief', 'Senator Mark Kirk', 'Bread for the World', 'University of Maryland, Baltimore', 'Nelson Mandela', 'Do Something', 'UNFPA', 'Qatar Foundation International', 'NPR Extra', 'United Nations Regional Information Centre- UNRIC', 'Tom Daley', 'Andres Iniesta', 'Rockefeller Foundation', 'Water.org', 'USAID - US Agency for International Development', 'The Global Network for Neglected Tropical Diseases', 'UN Web TV', 'Malala Fund', 'Sandra Rotman Centre', 'The Tony Elumelu Foundation', 'Kid President', 'Non-Profits on Facebook', 'Ambassador Samantha Power', 'Doctors Without Borders/ Médecins Sans Frontières (MSF)', 'Richard Branson', 'Global Good Challenge', 'Malaria No More UK', 'allAfrica.com', 'UNFPA - Burkina Faso', 'United Nations Mission in South Sudan (UNMISS)', 'BBC Trending', 'Run for Polio in Venice', 'Population Services International', 'V-Day', 'Sustainable Development Goals Fund', 'CAFOD', 'SportsUnited - U.S. Department of State', 'Tennessee Council for the Social Studies', 'Harvard Business Review', 'Syngenta', 'Unicef Afghanistan', 'The Verge', 'Solidays', 'ViralNova', 'SumOfUs', 'TOMS', 'New Jersey Geographic Alliance', 'Target', 'Global Health and Diplomacy', 'United Nations Development Programme - UNDP', 'Yvonne Chaka Chaka', 'Microsoft Research', 'IRD', 'Stanford Graduate School of Business', 'Ashton Kutcher', 'Unicef DR Congo', 'Results for Development Institute', 'Astronomy Picture of the Day (APOD)', 'Vox', '(RED)', 'Bill & Melinda Gates Foundation', 'Nature', 'YouTube', 'The Voice', 'TEDx', 'MTV Issues', 'A Plus', 'ShelterBox', 'Civicus: World Alliance for Citizen Participation', 'Unicef Burundi', 'UN-HABITAT', 'Aeon Magazine', \"The United Nations Girls' Education Initiative -(UNGEI)\", 'Facebook Games', 'UNITAID', 'The Global Fund to Fight AIDS, Tuberculosis and Malaria', 'Rotaract Club Barcelona', 'Child Health Now', 'TED Fellows', 'Better Immunization Data Initiative', 'Co.Create', 'SOIL (Sustainable Organic Integrated Livelihoods)', 'Kansas Council for the Social Studies', 'TED-Ed', 'Mashable', 'World Economic Forum - Gender', 'BBC One', 'Microsoft Flight', 'NRDC (Natural Resources Defense Council)', 'UNAIDS', 'Ted Turner', 'Sesame Workshop', 'United Nations Millennium Campaign', 'P&G', 'NPR Politics', 'Greenpeace USA', 'Power the World', 'Global Poverty Project', 'TechCrunch', 'WASH United', 'Khan Academy', 'Banque mondiale', 'Nieman Journalism Lab', 'The Wellbeing Foundation', 'We Are Africa United', 'SayNO - UNiTE to End Violence Against Women', 'International Federation of Red Cross and Red Crescent Societies', 'Desmond Tutu HIV Foundation', 'Science', 'ProPublica', 'The Cut', 'UNICEF Iran', 'BlackGirlsCode', 'UN Women', \"Department of State -- Office of Global Women's Issues\", 'Care2Prevent Auxiliary Board', 'International Trachoma Initiative', 'Facebook Security', 'Gavi, the Vaccine Alliance', 'California Charter Schools Association', 'Sanitation and Water for All', 'The Huffington Post', 'Senator Patrick Leahy', 'International Atomic Energy Agency (IAEA)', 'Rio+Social', 'Random Acts Revolution', 'SXSW', 'The Metropolitan Museum of Art, New York', 'PSY', 'Today Show', 'Bayer', 'Internet Explorer', 'Facebook Diversity', 'Operation ASHA', 'The Georgia Geographic Alliance', 'NBA', 'CityClub Seattle', 'MediaStorm', 'Whole Foods Market', \"International Women's Day\", 'Campaign for Australian Aid', 'The Case Foundation', 'Virgin Galactic', 'Best Buy', 'The Nature Conservancy', 'Kula Project', 'The Tonight Show Starring Jimmy Fallon', 'Radiolab', 'TEDActive', 'Human Rights Watch', 'Teaching Tolerance', 'Colonial Williamsburg', 'UNESCO', 'WOW at Southbank Centre', 'PATH Drug Development', 'EA SPORTS FIFA', 'TED Books', 'Oxfam Ireland', 'Microsoft Tag', 'Snap Judgment', 'Acumen', \"Women's Policy, Inc.\", 'Overdrive Interactive', 'United Nations Commission on the Status of Women (CSW)', 'Jhpiego', 'Seattle Foundation', 'Jack Wills', 'Texas Council for the Social Studies', 'EA SPORTS PGA TOUR', 'The Malaria Policy Center', 'FutureWeWant', 'Global Fund Advocates Network', 'Partners In Health', 'Dexter', 'Real Simple', 'Plus Social Good', 'AOL', 'HP', 'Sevenly', 'On Point Radio', 'Global Entrepreneurship Week', 'George Takei', 'Global Shapers Monterrey Hub', 'World Economic Forum', 'The Brookings Institution', 'Fast Company', 'United Nations Association of New Zealand - UNANZ', 'Windows', 'Outlook', 'The Square', 'The Ella Rose Collection', 'Thrivent Financial', 'President Bill Clinton', 'Unite For Sight', 'TEDxChange', 'UNICEF Albania', 'WIRED', 'American Museum of Natural History', 'The Gilder Lehrman Institute of American History', 'Global Alliance for Improved Nutrition', 'Social Studies', 'Xbox', 'BRAC', 'PAHO-WHO', '10x10 - Girl Rising', 'Bradshaw Foundation', 'MDG Health Envoy', 'UNICEF', 'TakePart.com', 'U.S. Global Leadership Coalition (USGLC)', 'Massachusetts Council for the Social Studies', 'National Council for the Social Studies', 'United Nations OCHA', 'BBC News', 'TED.com', 'High Tech Teachers', 'Top Gear', 'Devex', 'Dell', 'charity: water', 'Helen Clark', 'Washington Global Health Alliance', 'African Union', 'A Path Appears', 'Congressman Jim Moran', 'Global Shapers', 'Oklahoma Council for the Social Studies', 'TechWomen', 'SJSU Social Science Teacher Preparation', 'The Next Web', 'The Late Show with Stephen Colbert', 'Barack Obama', 'AJ+', 'Vijender Singh', 'United Nations Assistance Mission in Somalia - UNSOM', 'United Nations Photo', 'OWN: Oprah Winfrey Network', 'Colorado Council for the Social Studies', 'Reuters', 'Journalists on Facebook', 'Microsoft Lumia', 'UN Radio', 'This American Life', \"The U.S. President's Emergency Plan for AIDS Relief (PEPFAR)\", 'Virgin Produced.', 'Shot@Life', 'Education Week', 'Enough Food IF', 'A Mighty Girl', 'Minnesota Council for the Social Studies', 'Pau Gasol', 'UC San Francisco (UCSF)', 'Global Partnership for Education', 'Constitutional Rights Foundation', 'UNEP', 'Surge for Water', 'Mom Bloggers for Social Good', 'PBL for Teachers', 'Chipotle Mexican Grill', 'Ashoka', 'CNN International', 'Coca-Cola', 'MythBusters', 'GE', 'Guardian global development']\n",
      "train_graph has 712 nodes and 1705 edges\n",
      "\n",
      "top jaccard scores for Bill Gates:\n",
      "[(('Bill Gates', 'Global Citizen'), 0.16216216216216217), (('Bill Gates', 'Bill & Melinda Gates Foundation'), 0.10344827586206896), (('Bill Gates', 'Grand Challenges Canada'), 0.09375), (('Bill Gates', 'I fucking love science'), 0.09375), (('Bill Gates', 'Girl Effect'), 0.09090909090909091)]\n",
      "jaccard accuracy=0.2\n",
      "\n",
      "top path scores for Bill Gates for beta=.1:\n",
      "[(('Bill Gates', 'Bill & Melinda Gates Foundation'), 0.06000000000000001), (('Bill Gates', 'Global Citizen'), 0.06000000000000001), (('Bill Gates', 'Gavi, the Vaccine Alliance'), 0.04000000000000001), (('Bill Gates', 'FutureWeWant'), 0.030000000000000006), (('Bill Gates', 'Girl Effect'), 0.030000000000000006)]\n",
      "path accuracy for beta .1=0.4\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    FYI: This takes ~10-15 seconds to run on my laptop.\n",
    "    \"\"\"\n",
    "    download_data()\n",
    "    graph = read_graph()\n",
    "    print('graph has %d nodes and %d edges' %\n",
    "          (graph.order(), graph.number_of_edges()))\n",
    "    subgraph = get_subgraph(graph, 2)\n",
    "    print('subgraph has %d nodes and %d edges' %\n",
    "          (subgraph.order(), subgraph.number_of_edges()))\n",
    "    print('norm_cut scores by max_depth:')\n",
    "    print(score_max_depths(subgraph, range(1,5)))\n",
    "    clusters = partition_girvan_newman(subgraph, 3)\n",
    "    print('first partition: cluster 1 has %d nodes and cluster 2 has %d nodes' %\n",
    "          (clusters[0].order(), clusters[1].order()))\n",
    "    print('cluster 2 nodes:')\n",
    "    print(clusters[1].nodes())\n",
    "\n",
    "    test_node = 'Bill Gates'\n",
    "    train_graph = make_training_graph(subgraph, test_node, 5)\n",
    "    print('train_graph has %d nodes and %d edges' %\n",
    "          (train_graph.order(), train_graph.number_of_edges()))\n",
    "\n",
    "\n",
    "    jaccard_scores = jaccard(train_graph, test_node, 5)\n",
    "    print('\\ntop jaccard scores for Bill Gates:')\n",
    "    print(jaccard_scores)\n",
    "    print('jaccard accuracy=%g' %\n",
    "          evaluate([x[0] for x in jaccard_scores], subgraph))\n",
    "\n",
    "    path_scores = path_score(train_graph, test_node, k=5, beta=.1)\n",
    "    print('\\ntop path scores for Bill Gates for beta=.1:')\n",
    "    print(path_scores)\n",
    "    print('path accuracy for beta .1=%g' %\n",
    "          evaluate([x[0] for x in path_scores], subgraph))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
